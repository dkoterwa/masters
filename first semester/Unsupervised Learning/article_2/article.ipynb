{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing dimension of text data: an example of applying PCA and t-SNE to word embeddings \n",
    "\n",
    "In this notebook I am applying dimensionality reduction techniques to preprocessed lyrics of the songs.\n",
    "Dataset is a set of lyrics of 48 various songs, from poetry to Justin Bieber. <br>\n",
    "\n",
    "I've wanted to see how much varianced can be collected by reducing the dimensions of word vectors from 300 to 2. <br>\n",
    "Actually I will call these vectors \"song vectors\" because each of these vectors is an averaged embedding of all words existing in the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Songs preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import string\n",
    "import os\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Set parameters for plots\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mrcParams\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlines.color\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpatch.edgecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtext.color\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maxes.facecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maxes.edgecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mlightgray\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maxes.labelcolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mxtick.color\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mytick.color\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgrid.color\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mlightgray\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfigure.facecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfigure.edgecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msavefig.facecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msavefig.edgecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Set parameters for plots\n",
    "plt.rcParams.update({\n",
    "    \"lines.color\": \"white\",\n",
    "    \"patch.edgecolor\": \"white\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"lightgray\",\n",
    "    \"axes.labelcolor\": \"white\",\n",
    "    \"xtick.color\": \"white\",\n",
    "    \"ytick.color\": \"white\",\n",
    "    \"grid.color\": \"lightgray\",\n",
    "    \"figure.facecolor\": \"black\",\n",
    "    \"figure.edgecolor\": \"black\",\n",
    "    \"savefig.facecolor\": \"black\",\n",
    "    \"savefig.edgecolor\": \"black\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory\n",
    "folder_path = \"/Volumes/Macintosh HD – dane/GitHub/masters/first semester/Unsupervised Learning/article_2/data\"\n",
    "os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which creates a list, each position of a final list is a list of song words\n",
    "def get_lyrics(list_of_songs = []):\n",
    "    \n",
    "    for file in os.listdir(): # iterate through directory\n",
    "        \n",
    "        if file.endswith(\".txt\"): # open each file\n",
    "            file_path = f\"{folder_path}/{file}\"\n",
    "\n",
    "            lyrics = pd.read_csv(file_path, sep='\\b', quoting=3, encoding='utf-8', header=None, names=['lines'])\n",
    "            lyrics_list = lyrics['lines'].tolist() # transform song words into a list\n",
    "            list_of_songs.append(lyrics_list)\n",
    "            \n",
    "    return list_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which outputs a list of vectors created from the lyrics\n",
    "def lyrics_preprocess(songs_list, stopwords, songs_vectors = [], stop_words_check = []):\n",
    "\n",
    "    for song in tqdm(songs_list):\n",
    "\n",
    "        text = \" \".join(song) # create a list of words\n",
    "        doc = nlp(text)\n",
    "\n",
    "        tokens  = [token.text for token in doc] # tokenize\n",
    "        tokens = [token.lemma_ for token in doc] # lemmantize\n",
    "\n",
    "        tokens = [token for token in tokens if token not in string.punctuation] # remove punctuation\n",
    "        tokens = [token.lower() for token in tokens] # lower words\n",
    "        tokens = [item for item in tokens if item not in stopwords] # remove stopwords\n",
    "\n",
    "        for word in tokens: # checking if any stop word somehow was not deleted\n",
    "            \n",
    "            if word in stopwords:\n",
    "                stop_words_check.append(word)\n",
    "            assert len(stop_words_check) == 0, 'Error: not all of the stopwords were deleted from text'\n",
    "        \n",
    "        tokens_concat = \" \".join(tokens) # joining words into one string\n",
    "        sentence_vec = nlp(tokens_concat) # vectorizing\n",
    "        songs_vectors.append(sentence_vec.vector) #saving song vector\n",
    "        \n",
    "    return songs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which creates column names from files names in the directory\n",
    "def create_column_names(list_of_columns = []):\n",
    "\n",
    "    for file in os.listdir():\n",
    "        file = file[:-4]\n",
    "        list_of_columns.append(file)\n",
    "\n",
    "        if '.DS_S' in list_of_columns:\n",
    "            list_of_columns.remove('.DS_S')\n",
    "\n",
    "    return list_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading stop words\n",
    "stop = STOP_WORDS\n",
    "stop.update(['...', '....', '1', '2', '3', '4', '5', 'chorus', ':]', '[:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exctracting songs vectors\n",
    "lyrics = get_lyrics()\n",
    "lyrics_vectors = lyrics_preprocess(lyrics, stopwords = stop)\n",
    "df_columns = create_column_names()\n",
    "\n",
    "songs_df = pd.DataFrame(lyrics_vectors).T\n",
    "songs_df.columns = df_columns\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe\n",
    "songs_df.to_csv('/Volumes/Macintosh HD – dane/GitHub/masters/first semester/Unsupervised Learning/article_2/songs_vectors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataframe\n",
    "songs_df = pd.read_csv(\"/Volumes/Macintosh HD – dane/GitHub/masters/first semester/Unsupervised Learning/article_2/songs_vectors.csv\", index_col=0)\n",
    "column_names = songs_df.columns\n",
    "songs_df = songs_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between songs\n",
    "cos_sim = []\n",
    "for column in column_names:\n",
    "    a = songs_df[column]\n",
    "    for i in column_names:\n",
    "        b = songs_df[i]\n",
    "        similarity = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "        cos_sim.append(similarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrix\n",
    "cos_sim_matrix = np.reshape(cos_sim, (48, 48))\n",
    "cos_sim_df = pd.DataFrame(cos_sim_matrix, index = column_names, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heatmap\n",
    "plt.rcParams[\"figure.figsize\"] = (20,11)\n",
    "fig = sns.heatmap(cos_sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "sc = StandardScaler()\n",
    "sc.fit(songs_df)\n",
    "df_transformed = sc.transform(songs_df)\n",
    "df_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA\n",
    "pca = PCA()\n",
    "df_pca = pca.fit_transform(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of explained variance\n",
    "variance_pca = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative explained variance\n",
    "cumulative_variance = np.cumsum(variance_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explained variance with 2 components: {}%\".format(np.round(np.sum(pca.explained_variance_ratio_) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scree plot\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "plt.bar(range(0, len(variance_pca)), \n",
    "        variance_pca, \n",
    "        alpha=0.5,\n",
    "        align='center',\n",
    "        label='Explained variance by each single principal component'\n",
    "       \n",
    ")\n",
    "plt.step(range(0, len(variance_pca)),\n",
    "        cumulative_variance,\n",
    "        where='mid',\n",
    "        label='Cumulative explained variance')\n",
    "plt.xlabel('Principal component index', fontsize=15)\n",
    "plt.ylabel('% of explained variance', fontsize=15)\n",
    "plt.xlim(-0.3, 15)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities with information about artists\n",
    "similarities_with_artists = []\n",
    "for column in column_names:\n",
    "    a = songs_df[column]\n",
    "    for i in column_names:\n",
    "        b = songs_df[i]\n",
    "        similarity = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "        similarities_with_artists.append([column, i, similarity]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_with_artists[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe and delete observations from diagonal of similarity matrix\n",
    "similarities_df = pd.DataFrame(similarities_with_artists, columns = ['artist1', 'artist2', 'cosine_similarity']).reset_index()\n",
    "similarities_df['cosine_similarity'] = np.round(similarities_df['cosine_similarity'], 7)\n",
    "similarities_df = similarities_df[(similarities_df['cosine_similarity'] != 1) | (similarities_df['artist1'] != similarities_df['artist2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare top 10 similarities\n",
    "top10 = similarities_df.sort_values(by='cosine_similarity', ascending=False).head(20).reset_index()\n",
    "top10 = top10.iloc[::2, :]\n",
    "top10['artist1_artist2'] = top10['artist1'] + ' and ' + top10['artist2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 similarities\n",
    "plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "fig = plt.bar(x='artist1_artist2', height='cosine_similarity', \n",
    "            data=top10,\n",
    "            width = 0.8)\n",
    "plt.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare bottom 10 similarities\n",
    "bottom10 = similarities_df.sort_values(by='cosine_similarity', ascending=False).tail(20).reset_index()\n",
    "bottom10 = bottom10.iloc[::2, :]\n",
    "bottom10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10['artist1_artist2'] = bottom10['artist1'] + ' and ' + bottom10['artist2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bottom 10 similarities\n",
    "plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "fig = plt.bar(x='artist1_artist2', height='cosine_similarity', \n",
    "            data=bottom10,\n",
    "            width = 0.8)\n",
    "plt.margins(x=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity = 5)\n",
    "tsne_fit = tsne.fit_transform(songs_df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reduced points\n",
    "fix, ax = plt.subplots()\n",
    "#plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "ax.scatter(tsne_fit[:, 0], \n",
    "            tsne_fit[:, 1])\n",
    "#plt.xlim(-20, 25)\n",
    "#plt.ylim(-15, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot points with songs names\n",
    "fix, ax = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (15,8)\n",
    "ax.scatter(tsne_fit[:, 0], \n",
    "            tsne_fit[:, 1])\n",
    "plt.xlim(-250, 250)\n",
    "#plt.ylim(-15, 25)\n",
    "\n",
    "xax = tsne_fit[:, 0]\n",
    "yax = tsne_fit[:, 1]\n",
    "for i, txt in enumerate(column_names):\n",
    "\n",
    "    not_to_move = ['ludacris', 'prince', 'patti-smith', 'michael-jackson', 'amy-winehouse', 'lin-manuel-miranda', 'disney', 'kanye-west']\n",
    "    if txt not in not_to_move:\n",
    "        ax.annotate(txt, (xax[i] - 0.3, yax[i] + 0.6))\n",
    "        \n",
    "    else:\n",
    "         ax.annotate(txt, (xax[i], yax[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
