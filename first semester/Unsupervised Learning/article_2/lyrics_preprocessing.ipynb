{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import string\n",
    "import os\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Volumes/Macintosh HD – dane/GitHub/masters/first semester/Unsupervised Learning/article_2/data\"\n",
    "os.chdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which creates a list, each position of a final list is a list of song words\n",
    "def get_lyrics(list_of_songs = []):\n",
    "    \n",
    "    for file in os.listdir(): # iterate through directory\n",
    "\n",
    "        if file.endswith(\".txt\"): # open each file\n",
    "            file_path = f\"{folder_path}/{file}\"\n",
    "\n",
    "            lyrics = pd.read_csv(file_path, sep='\\b', quoting=3, encoding='utf-8', header=None, names=['lines'])\n",
    "            lyrics_list = lyrics['lines'].tolist() # transform song words into a list\n",
    "            list_of_songs.append(lyrics_list)\n",
    "            \n",
    "    return list_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which outputs a list of vectors created from the lyrics\n",
    "def lyrics_preprocess(songs_list, stopwords, songs_vectors = [], stop_words_check = []):\n",
    "\n",
    "    for song in tqdm(songs_list):\n",
    "\n",
    "        text = \" \".join(song) # create a list of words\n",
    "        doc = nlp(text)\n",
    "\n",
    "        tokens  = [token.text for token in doc] # tokenize\n",
    "        tokens = [token.lemma_ for token in doc] # lemmantize\n",
    "\n",
    "        tokens = [token for token in tokens if token not in string.punctuation] # remove punctuation\n",
    "        tokens = [token.lower() for token in tokens] # lower words\n",
    "        tokens = [item for item in tokens if item not in stopwords] # remove stopwords\n",
    "\n",
    "        for word in tokens: # checking if any stop word somehow was not deleted\n",
    "            if word in stopwords:\n",
    "                stop_words_check.append(word)\n",
    "            assert len(stop_words_check) == 0, 'Error: not all of the stopwords were deleted from text'\n",
    "        \n",
    "        tokens_concat = \" \".join(tokens) # joining words into one string\n",
    "        sentence_vec = nlp(tokens_concat) # vectorizing\n",
    "        songs_vectors.append(sentence_vec.vector) #saving song vector\n",
    "        \n",
    "    return songs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which creates column names from files names in the directory\n",
    "def create_column_names(list_of_columns = []):\n",
    "\n",
    "    for file in os.listdir():\n",
    "\n",
    "        \n",
    "        file = file[:-4]\n",
    "        list_of_columns.append(file)\n",
    "\n",
    "        if '.DS_S' in list_of_columns:\n",
    "            list_of_columns.remove('.DS_S')\n",
    "\n",
    "    return list_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = STOP_WORDS\n",
    "stop.update(['...', '....', '1', '2', '3', '4', '5', 'chorus', ':]', '[:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [04:32<00:00,  5.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Exctracting songs vectors\n",
    "lyrics = get_lyrics()\n",
    "lyrics_vectors = lyrics_preprocess(lyrics, stopwords = stop)\n",
    "df_columns = create_column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.DataFrame(lyrics_vectors).T\n",
    "songs_df.columns = df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prince</th>\n",
       "      <th>dickinson</th>\n",
       "      <th>notorious-big</th>\n",
       "      <th>beatles</th>\n",
       "      <th>bob-dylan</th>\n",
       "      <th>bjork</th>\n",
       "      <th>johnny-cash</th>\n",
       "      <th>disney</th>\n",
       "      <th>janisjoplin</th>\n",
       "      <th>kanye</th>\n",
       "      <th>...</th>\n",
       "      <th>r-kelly</th>\n",
       "      <th>drake</th>\n",
       "      <th>britney-spears</th>\n",
       "      <th>bruce-springsteen</th>\n",
       "      <th>nicki-minaj</th>\n",
       "      <th>kanye-west</th>\n",
       "      <th>paul-simon</th>\n",
       "      <th>nickelback</th>\n",
       "      <th>eminem</th>\n",
       "      <th>bruno-mars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488899</td>\n",
       "      <td>-0.151497</td>\n",
       "      <td>0.281931</td>\n",
       "      <td>0.866229</td>\n",
       "      <td>0.332050</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>-0.052686</td>\n",
       "      <td>0.628423</td>\n",
       "      <td>1.015842</td>\n",
       "      <td>0.393763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799079</td>\n",
       "      <td>0.404629</td>\n",
       "      <td>1.180542</td>\n",
       "      <td>0.407606</td>\n",
       "      <td>0.457071</td>\n",
       "      <td>0.121589</td>\n",
       "      <td>0.254363</td>\n",
       "      <td>0.492601</td>\n",
       "      <td>0.342824</td>\n",
       "      <td>1.013985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.610341</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>1.261264</td>\n",
       "      <td>1.241061</td>\n",
       "      <td>1.255925</td>\n",
       "      <td>1.078212</td>\n",
       "      <td>1.197751</td>\n",
       "      <td>1.076042</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>1.128111</td>\n",
       "      <td>...</td>\n",
       "      <td>1.237406</td>\n",
       "      <td>1.262244</td>\n",
       "      <td>1.398354</td>\n",
       "      <td>1.339310</td>\n",
       "      <td>1.205130</td>\n",
       "      <td>1.069831</td>\n",
       "      <td>0.998072</td>\n",
       "      <td>1.366088</td>\n",
       "      <td>1.295770</td>\n",
       "      <td>1.322053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.936098</td>\n",
       "      <td>-1.636477</td>\n",
       "      <td>-2.027798</td>\n",
       "      <td>-2.377264</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>-2.123817</td>\n",
       "      <td>-2.158009</td>\n",
       "      <td>-1.888964</td>\n",
       "      <td>-2.310341</td>\n",
       "      <td>-2.193906</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.352120</td>\n",
       "      <td>-2.181932</td>\n",
       "      <td>-2.494427</td>\n",
       "      <td>-2.476290</td>\n",
       "      <td>-2.033452</td>\n",
       "      <td>-2.097285</td>\n",
       "      <td>-2.303176</td>\n",
       "      <td>-2.186932</td>\n",
       "      <td>-2.072237</td>\n",
       "      <td>-2.356970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.821185</td>\n",
       "      <td>-0.192223</td>\n",
       "      <td>-0.096713</td>\n",
       "      <td>-0.816632</td>\n",
       "      <td>-0.467427</td>\n",
       "      <td>-0.406551</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.709705</td>\n",
       "      <td>-1.149756</td>\n",
       "      <td>-0.394666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.881137</td>\n",
       "      <td>-0.501777</td>\n",
       "      <td>-1.125783</td>\n",
       "      <td>-0.479958</td>\n",
       "      <td>-0.329150</td>\n",
       "      <td>-0.649858</td>\n",
       "      <td>-0.553310</td>\n",
       "      <td>-0.386956</td>\n",
       "      <td>-0.240733</td>\n",
       "      <td>-0.748238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.371704</td>\n",
       "      <td>0.994015</td>\n",
       "      <td>-0.321496</td>\n",
       "      <td>-0.149797</td>\n",
       "      <td>0.647207</td>\n",
       "      <td>0.377207</td>\n",
       "      <td>0.430123</td>\n",
       "      <td>0.280071</td>\n",
       "      <td>-0.508992</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039799</td>\n",
       "      <td>-0.022557</td>\n",
       "      <td>-0.342595</td>\n",
       "      <td>0.280042</td>\n",
       "      <td>-0.274202</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>0.717278</td>\n",
       "      <td>0.202165</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>-0.443886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prince  dickinson  notorious-big   beatles  bob-dylan     bjork  \\\n",
       "0  0.488899  -0.151497       0.281931  0.866229   0.332050  0.464633   \n",
       "1  1.610341   0.748771       1.261264  1.241061   1.255925  1.078212   \n",
       "2 -1.936098  -1.636477      -2.027798 -2.377264  -1.891242 -2.123817   \n",
       "3 -0.821185  -0.192223      -0.096713 -0.816632  -0.467427 -0.406551   \n",
       "4 -0.371704   0.994015      -0.321496 -0.149797   0.647207  0.377207   \n",
       "\n",
       "   johnny-cash    disney  janisjoplin     kanye  ...   r-kelly     drake  \\\n",
       "0    -0.052686  0.628423     1.015842  0.393763  ...  0.799079  0.404629   \n",
       "1     1.197751  1.076042     0.849392  1.128111  ...  1.237406  1.262244   \n",
       "2    -2.158009 -1.888964    -2.310341 -2.193906  ... -2.352120 -2.181932   \n",
       "3    -0.025675 -0.709705    -1.149756 -0.394666  ... -0.881137 -0.501777   \n",
       "4     0.430123  0.280071    -0.508992  0.116053  ... -0.039799 -0.022557   \n",
       "\n",
       "   britney-spears  bruce-springsteen  nicki-minaj  kanye-west  paul-simon  \\\n",
       "0        1.180542           0.407606     0.457071    0.121589    0.254363   \n",
       "1        1.398354           1.339310     1.205130    1.069831    0.998072   \n",
       "2       -2.494427          -2.476290    -2.033452   -2.097285   -2.303176   \n",
       "3       -1.125783          -0.479958    -0.329150   -0.649858   -0.553310   \n",
       "4       -0.342595           0.280042    -0.274202   -0.136441    0.717278   \n",
       "\n",
       "   nickelback    eminem  bruno-mars  \n",
       "0    0.492601  0.342824    1.013985  \n",
       "1    1.366088  1.295770    1.322053  \n",
       "2   -2.186932 -2.072237   -2.356970  \n",
       "3   -0.386956 -0.240733   -0.748238  \n",
       "4    0.202165 -0.023635   -0.443886  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df.to_csv('/Volumes/Macintosh HD – dane/GitHub/masters/first semester/Unsupervised Learning/article_2/songs_vectors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
